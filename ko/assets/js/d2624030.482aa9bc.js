"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[807],{9909:n=>{n.exports=JSON.parse('{"blogPosts":[{"id":"littlebird","metadata":{"permalink":"/ko/littlebird","source":"@site/i18n/ko/docusaurus-plugin-content-blog/2023-04-18-littlebird/index.mdx","title":"LittleBird: Efficient Faster & Longer Transformer for Question Answering","description":"Describing the How to implement the LittleBird sparse attention transformer for question answering","date":"2023-04-18T00:00:00.000Z","formattedDate":"2023\ub144 4\uc6d4 18\uc77c","tags":[{"label":"nlp","permalink":"/ko/tags/nlp"},{"label":"koreannlp","permalink":"/ko/tags/koreannlp"},{"label":"deeplearning","permalink":"/ko/tags/deeplearning"},{"label":"sparse attention","permalink":"/ko/tags/sparse-attention"},{"label":"seq2seq","permalink":"/ko/tags/seq-2-seq"},{"label":"transformer variant","permalink":"/ko/tags/transformer-variant"},{"label":"paper implementation","permalink":"/ko/tags/paper-implementation"}],"readingTime":21.48,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"littlebird","title":"LittleBird: Efficient Faster & Longer Transformer for Question Answering","tags":["nlp","koreannlp","deeplearning","sparse attention","seq2seq","transformer variant","paper implementation"],"description":"Describing the How to implement the LittleBird sparse attention transformer for question answering","keywords":["nlp","transformers","koreannlp","korquad","deeplearning","sparse attention","littlebird"]}},"content":"import Figure from \\"../../../../src/components/figure\\";\\nimport full_sparse_attn_img from \\"../../../../static/img/2023-04-18-littlebird/full_sparse_attn.png\\";\\nimport block_tokens_ex_img from \\"../../../../static/img/2023-04-18-littlebird/blocked_tokens_example.png\\";\\nimport first_two_rows_img from \\"../../../../static/img/2023-04-18-littlebird/first_two_rows.png\\";\\nimport middle_rows_img from \\"../../../../static/img/2023-04-18-littlebird/middle_rows.png\\";\\nimport last_row_img from \\"../../../../static/img/2023-04-18-littlebird/last_row.png\\";\\nimport sliding_window_broken_down from \\"../../../../static/img/2023-04-18-littlebird/sliding_window_broken_down.png\\";\\n\\n\uc774 \uac1c\uc2dc\ubb3c\uc5d0\uc11c LittleBird<sub>[1]</sub> \ubaa8\ub378 \uad6c\uc870 \ubc0f \uad6c\ud604\ud558\ub294 \ubc29\ubc95\uc5d0 \ub300\ud574\uc11c \uc0b4\ud3b4\ubcf4\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4.\\n\\n![asdf](../../../../static/img/2023-04-18-littlebird/littlebird_layer.png)\\n\\n## \uc18c\uac1c\\n\\nLittleBird\ub294 \uce74\uce74\uc624\uc5d4\ud130\ud504\ub77c\uc774\uc988\uac00 \uc9c1\uc811 \uac1c\ubc1c\ud55c Sparse Attention Transformer \ubaa8\ub378\uc774\uba70, BigBird<sub>[2]</sub>\uc758 \uc815\ud655\ub3c4\ub97c \uc720\uc9c0\ud558\uba74\uc11c \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9\uacfc \ubaa8\ub378\uc758 \uc18d\ub3c4\ub97c \uac1c\uc120\ud569\ub2c8\ub2e4. \uac04\ub2e8\ud558\uac8c \ub9d0\uc500 \ub4dc\ub9ac\uc790\uba74, LittleBird\ub294 BigBird\uc758 Sliding Window Attention\uacfc LUNA<sub>[3]</sub>\uc758 Pack & Unpack Attention\uc744 \ud569\uce58\uace0, ALiBi<sub>[4]</sub> \uae30\ubc18\ud55c \uc0c8\ub85c\uc6b4 \uc591\ubc29\ud5a5 \uc704\uce58 \uc815\ubcf4\ub97c \ud45c\ud604\ud558\ub294 \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud558\ub294 \ubaa8\ub378\uc785\ub2c8\ub2e4.\\n\\nLittleBird \uad6c\uc870\ub294 \ud06c\uac8c LUNA, Sliding Window Attention, BiALiBi (\uc591\ubc29\ud5a5 ALiBi) \uc138 \uac1c\uc758 \ubd80\ubd84\uc73c\ub85c \ub098\ub20c \uc218 \uc788\uace0, LittleBird \uacf5\uc2dd\uc744 \uc0b4\ud3b4\ubcf4\uba74\uc11c \uad6c\ud604\ud558\ub294 \ubc29\ubc95\uc744 \uc124\uba85\ud574\ubcf4\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4.\\n\\n:::note\\n\\n\ubaa8\ub378\uc5d0 \uad00\ub828\ud55c \uc774\ub860\uc801\uc778 \ubd80\ubd84 \ub610\ub294 \ud559\uc2b5\ud558\ub294 \uacfc\uc815\uc744 \uc9c1\uc811 \ub17c\ubb38\uc744 \ud1b5\ud574 \ud655\uc778\ud558\uc2dc\uae38 \ubc14\ub78d\ub2c8\ub2e4.\\n\\n:::\\n\\n## \uacf5\uc2dd\\n\\n### LittleBird \ub808\uc774\uc5b4\\n\\n$$\\n\\\\begin{aligned}\\nC_p = Attn(P,X) \\\\\\\\\\nP^{\\\\prime} = LayerNorm(C_p + P) \\\\\\\\\\nC_x = USWAttn(X, C_p) \\\\\\\\\\nA = LayerNorm(C_x + X) \\\\\\\\\\nX^{\\\\prime} = LayerNorm(FFN(A) + A)\\n\\\\end{aligned}\\n$$\\n\\n\uc5ec\uae30\uc11c $X \\\\in \\\\R^{l \\\\text{ x } d}$\ub294 \uc785\ub825 \uc2dc\ud000\uc2a4\uc778\ub370 $l$\uc640 $d$\ub294 \uac01\uac01 \uc2dc\ud000\uc2a4 \uae38\uc774\uc640 \ud1a0\ud070 \uc784\ubca0\ub529\uc758 \ucc28\uc6d0\uc785\ub2c8\ub2e4.\\n$P \\\\in \\\\R^{s \\\\text{ x } d}$\ub294 Pack Attention\uc758 projection \ud589\ub82c\uc778\ub370, $s$\ub294 \ucd95\uc18c\ud560 \uc2dc\ud000\uc2a4 \uae38\uc774\uc785\ub2c8\ub2e4.\\n\\n### Attention\\n\\n$$\\nAttn(X,C) = \\\\sigma(\\\\frac{Q(X)K(C)^T}{\\\\sqrt{d}})V(C)\\n$$\\n\\n$$\\nUSWAttn(X, C_p) = \\\\\\\\\\n\\\\begin{aligned}\\n\\\\sigma(\\\\frac{Q(X)[K(C_P);K(X)]^T}{\\\\sqrt{d}} - [D_p;D]^T) \\\\\\\\ \\\\cdot [V(C_p);V(X)]\\n\\\\end{aligned}\\n$$\\n\\n\uc5ec\uae30\uc11c $[A;B]$\ub294 $A$\uc640 $B$\uc758 \uc811\ud569\uc774\uba70, $USWAttn$\ub294 Unpack & Sliding Window Attention\uc744 \uc758\ubbf8\ud55c\ub2e4.\\n\\n### BiALiBi\\n\\n$$\\nD_p = (\\n    \\\\frac{\\\\beta + \\\\gamma}{2}b)J_{s,l}\\n$$\\n\\n$$\\nD_{i,j} = \\\\begin{cases}\\n    0, &\\\\text{for } i=j\\\\\\\\\\n    \\\\alpha, &\\\\text{for } i=0 &\\\\text{or } j=0\\\\\\\\\\n    \\\\beta(i-j), &\\\\text{for } i>j\\\\\\\\\\n    \\\\gamma(j-i), &\\\\text{for } i<j\\n\\\\end{cases}\\n$$\\n\\n$D_p \\\\in \\\\R^{s \\\\text{ x } l}$\ub294 Pack Attention\uc758 \uc704\uce58 \uc815\ubcf4 \ud45c\ud604\ud558\ub294 \ud589\ub82c\uc774\uba70, $J_{s,l}$\ub294 \ud06c\uae30 $s$ x $l$\uc778 all-ones \ud589\ub82c\uc785\ub2c8\ub2e4. $D_{i,j}$\ub294 BiALiBi\ub85c\uc11c, LittleBird \ub17c\ubb38\uc5d0\uc11c Sliding Window Attention \uc704\uce58 \uc815\ubcf4 \ud45c\ud604\ud558\ub294 \ud589\ub82c\ub85c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. $\\\\alpha$, $\\\\beta$, $\\\\gamma$\ub294 \ud559\uc2b5\ud558\ub294 \ud30c\ub77c\ubbf8\ud130\uc785\ub2c8\ub2e4.\\n\\n## \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\\n\\n\ubaa8\ub378 \uad6c\ud604\ud558\uae30 \uc804\uc5d0 \ud544\uc218\uc801\uc778 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\ub4e4\uc774 \ubb54\uc9c0 \uc54c\uba74 \uc88b\uc744 \uac83 \uac19\uc2b5\ub2c8\ub2e4. \uc55e\uc73c\ub85c\uc758 \ucf54\ub4dc \uc608\uc2dc\uc5d0\uc11c \uc0ac\uc6a9\ud560 \uc608\uc815\uc785\ub2c8\ub2e4.\\n\\n| \ubcc0\uc218                | dtype | \uae30\ubcf8\uac12 | \uc124\uba85                                         |\\n| :------------------ | :---- | :----: | :------------------------------------------- |\\n| seq_len             | int   |  None  | \uc785\ub825 \uc2dc\ud000\uc2a4 \uae38\uc774                             |\\n| pack_len            | int   |  None  | projection \ud589\ub82c \uae38\uc774                         |\\n| d_model             | int   |  512   | \uc784\ubca0\ub529 \ucc28\uc6d0                                  |\\n| d_ff                | int   |  2048  | FeedForward layer \ucc28\uc6d0                       |\\n| num_attention_heads | int   |   8    | -                                            |\\n| num_heads           | int   |   8    | num_attention_heads\uc640 \ub3d9\uc77c                   |\\n| dropout_p           | float |  0.1   | -                                            |\\n| block_size          | int   |   64   | USWAttn \uacc4\uc0b0 \uc2dc \ube14\ub85d size                    |\\n| window_size         | int   |   3    | Sliding Window Attention \uacc4\uc0b0 \uc2dc window size |\\n\\n## LittleBird \ub808\uc774\uc5b4\\n\\n> \uc232\uc744 \ubcf4\uace0 \ub098\ubb34\ub97c \ubcf4\ub77c\\n\\nLittleBirdModel\uc744 \ud0d1\ub2e4\uc6b4(Top-Down) \ubc29\uc2dd\uc73c\ub85c LittleBirdLayer \ud074\ub798\uc2a4\ubd80\ud130 \uad6c\ud604\ud574\ubcf4\uc8e0. \uc704\uc758 \uacf5\uc2dd\uc744 \ubcf4\uc2dc\uba74, LittleBirdLayer\ub294 LayerNorm 3 \uac1c, FeedForwardNetwork \ud558\ub098, MultiHeadAttention \ud558\ub098, \uadf8\ub9ac\uace0 USWAttn \ud558\ub098\ub9cc\uc73c\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc544\ub798\uc640 \uac19\uc774 \uac04\ub2e8\ud558\uac8c LittleBirdLayer\ub97c \uc815\uc758\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n### \ucd08\uae30\ud654\\n\\n```python\\nclass LittleBirdLayer(nn.Module):\\n    def __init__(...) -> None:\\n        ...\\n\\n        self.pack_attn = PackAttention(d_model, num_attention_heads)\\n        self.unpack_sliding_attn = UnpackSlidingWindowAttention(\\n            seq_len, pack_len, d_model, num_attention_heads, block_size\\n        )\\n        self.feed_forward = PositionwiseFeedForwardNetwork(d_model, d_ff, dropout_p)\\n\\n        self.pack_attn_layer_norm = nn.LayerNorm(d_model)\\n        self.unpack_sliding_attn_layer_norm = nn.LayerNorm(d_model)\\n        self.ffn_layer_norm = nn.LayerNorm(d_model)\\n```\\n\\n### Forward\\n\\n\uacc4\uc0b0\uc744 \uac01\uac01\uc758 \ub808\uc774\uc5b4\ub85c \ucd94\uc0c1\ud654\ud588\uae30 \ub54c\ubb38\uc5d0 \uc704\uc758 \uacf5\uc2dd\uc5d0\uc11c \uc81c\uc2dc\ud55c\ub300\ub85c \uac70\uc758 \ub611\uac19\uc774 \uad6c\ud604\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n\ubaa8\ub378\uc5d0\ub294 \uc5ec\ub7ec \uac1c\uc758 LittleBird \ub808\uc774\uc5b4\uac00 \uc788\uace0, \uac01\uac01 \ub2e4\uc74c \ub808\uc774\uc5b4\uc5d0 $P$\uc640 $X$\ub97c \uc785\ub825\ud558\uae30 \uc704\ud574\uc11c $P\'$\uc640 $X\'$ \ub458\ub2e4 \ubc18\ud658\ud569\ub2c8\ub2e4.\\n\\n\\n```python\\n    def forward(\\n        self,\\n        P: torch.Tensor,\\n        X: torch.Tensor,\\n        attention_mask: torch.Tensor\\n    ):\\n        Cp = self.pack_attn(P, X, attention_mask)\\n        P0 = self.pack_attn_layer_norm(Cp + P)\\n\\n        Cx = self.unpack_sliding_attn(X, Cp, attention_mask)\\n        A = self.unpack_sliding_attn_layer_norm(Cx + X)\\n\\n        X0 = self.ffn_layer_norm(self.feed_forward(A) + A)\\n\\n        return P0, X0\\n```\\n\\n\uc774\uc81c \ub354 \uae4a\uc774 \ub4e4\uc5b4\uac00\uc11c PositionwiseFeedForwardNetwork, PackAttention, \uadf8\ub9ac\uace0 UnpackSlidingWindowAttention \uad6c\ud604\ud574\ubd05\uc2dc\ub2e4.\\n\\n## Feed Forward\\n\\n\ubaa8\ub378\uc5d0 non-linearity \ucd94\uac00\ud558\ub294 \ubaa9\uc801\uc73c\ub85c $C_x$ (context)\ub97c \uacc4\uc0b0\ud55c \ub2e4\uc74c\uc5d0 \uc774\ub97c FeedForward Network\ub85c \ud1b5\uacfc\ud569\ub2c8\ub2e4.\\n\\n\uc774\ub294 \uc544\ub798\uc640 \uac19\uc774 _Attention is all you need_ \ub17c\ubb38\uc5d0\uc11c \uc124\uba85\ud55c\ub300\ub85c \uc27d\uac8c \uad6c\ud604\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n```python\\nclass PositionwiseFeedForwardNetwork(nn.Module):\\n    def __init__(...) -> None:\\n        super(PositionwiseFeedForwardNetwork, self).__init__()\\n        self.feed_forward = nn.Sequential(\\n            nn.Linear(d_model, d_ff),\\n            nn.Dropout(dropout_p),\\n            nn.ReLU(),\\n            nn.Linear(d_ff, d_model),\\n            nn.Dropout(dropout_p),\\n        )\\n\\n    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\\n        return self.feed_forward(inputs)\\n```\\n\\n## PackAttention\\n\\nPack & Unpack Attention\uc758 Pack ($C_p$) \ubd80\ubd84\uc740 \uc77c\ubc18\uc801\uc778 Transformer \ubaa8\ub378\uc758 MultiHeadAttention\uacfc \ub3d9\uc77c\ud558\uc5ec \ud30c\uc774\ud1a0\uce58\uc758 MultiHeadAttention \ubaa8\ub4c8\uc744 \uc0ac\uc6a9\ud558\uba74 \uc774 \uc5ed\uc2dc\ub3c4 \uc27d\uac8c \uad6c\ud604\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n```python\\nclass PackAttention(nn.Module):\\n    def __init__(...):\\n        super(PackAttention, self).__init__()\\n        self.embed_dim = embed_dim\\n        self.num_heads = num_heads\\n\\n        self.mha = nn.MultiheadAttention(\\n            embed_dim=self.embed_dim, num_heads=self.num_heads, batch_first=True\\n        )\\n\\n    def forward(self, P: torch.Tensor, X: torch.Tensor, attention_mask: torch.Tensor):\\n        attn, _ = self.mha(P, X, X, attention_mask)\\n        return attn\\n```\\n\\n## USWAttention\\n\\n\uc9c0\uae08\uae4c\uc9c0 \ubaa8\ub378 \uad6c\ud604\ud558\ub294 \ub370 \ub531\ud788 \uc5b4\ub824\uc6c0\uc774 \uc5c6\uc5c8\uc8e0? \uc774\uc81c \ub09c\uc774\ub3c4 \uc870\uae08 \ub192\ud600\uc11c Unpack & Sliding Window Attention \ubd80\ubd84\ub3c4 \uad6c\ud604\ud574\ubcfc\uae4c\uc694?\\n\\n### \ucd08\uae30\ud654\\n\\n_Figure 2_ \ub610\ub294 \uc704\uc758 \uacf5\uc2dd\uc5d0\uc11c \uc81c\uc2dc\ud55c \uac83\ucc98\ub7fc UnpackSlidingWindowAttention\uc774 Unpack Attention\uacfc Global + Sliding Window Attention\uc758 \uc811\ud569\uc73c\ub85c \uad6c\uc131\ub3fc \uc788\uace0, \uc704\uce58 \uc815\ubcf4\ub97c \ud45c\ud604\ud558\uae30 \uc704\ud574\uc11c BiALiBi\ub3c4 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc774\ub97c \uace0\ub824\ud558\uc5ec UnpackSlidingWindowAttention \ud074\ub798\uc2a4\uc758 \ucd08\uae30\ud654 \ud568\uc218\ub97c \uc544\ub798\uc640 \uac19\uc774 \uad6c\ud604\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n```python\\nclass UnpackSlidingWindowAttention(nn.Module):\\n    def __init__(...):\\n        super(UnpackSlidingWindowAttention, self).__init__()\\n\\n        # \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\\n        self.attn_head_size = int(dim / num_attention_heads)\\n        self.num_attention_heads = num_attention_heads\\n        self.block_size = block_size\\n        self.seq_len = seq_len\\n        self.pack_len = pack_len\\n\\n        # QKV \uc120\ud615\ubcc0\ud658 \ub808\uc774\uc5b4\\n        self.Q = nn.Linear(dim, self.attn_head_size * num_attention_heads)\\n        self.K = nn.Linear(dim, self.attn_head_size * num_attention_heads)\\n        self.V = nn.Linear(dim, self.attn_head_size * num_attention_heads)\\n\\n        # \uc704\uce58 \uc815\ubcf4 \ud45c\ud604\ud558\ub294 BiALiBi \ud074\ub798\uc2a4\\n        self.bialibi = BidirectionalALiBi(\\n            self.num_attention_heads, self.seq_len\\n        )\\n        self.uniform_dist_mat = UniformDistanceMatrix(\\n            self.num_attention_heads, self.block_size, self.seq_len, self.pack_len\\n        )\\n\\n\\n        self.register_buffer(\\"middle_band_distance_indicies\\", None, persistent=False)\\n```\\n\\n### \uc120\ud615\ubcc0\ud658\\n\\n\ub9e8\uc704\uc5d0 \ucc98\uc74c\uc73c\ub85c scaling \uacc4\uc218 $rsqrt\\\\_d$\ub97c \ucd08\uae30\ud654\ud558\ub294\ub370 multihead attention\uc744 \uc0ac\uc6a9\ud558\ubbc0\ub85c \uc5ec\uae30\uc11c $rsqrt\\\\_d$\ub294 $embed\\\\_size / num\\\\_heads$ \uc785\ub2c8\ub2e4.\\n\\n\uadf8 \ub2e4\uc74c\uc73c\ub85c $X$\ub97c $Q$, $K$, $V$\uc640 \uadf8\ub9ac\uace0 $C_p$\ub97c $K$ \ubc0f $V$\uc758 \ub0b4\uc801\uc744 \uacc4\uc0b0\ud558\uace0, \uc774\ub97c $n\\\\_heads$\uc73c\ub85c \ub098\ub208 \ub2e4\uc74c\uc5d0 \ub9c8\uc9c0\ub9c9 \ub450\uac1c\uc758 \ucc28\uc6d0\uc774 $seq\\\\_len$\uacfc $d$\uc5d0 \ud574\ub2f9\ud558\uac8c\ub054 \ubc31\ud130\uc758 shape \ubcc0\uacbd\ud569\ub2c8\ub2e4.\\n\\n\\n```python\\n    def forward(self, X, Cp, ...)\\n\\n        ...\\n\\n        rsqrt_d = 1 / math.sqrt(self.attn_head_size)\\n\\n        batch_size, seq_len, dim = X.shape\\n\\n        query = transpose_for_scores(\\n            self.Q(X), self.num_attention_heads, self.attn_head_size\\n        )  # bsz, head, seq_len, head_dim\\n        key_x = transpose_for_scores(\\n            self.K(X), self.num_attention_heads, self.attn_head_size\\n        )  # bsz, head, seq_len, head_dim\\n        value_x = transpose_for_scores(\\n            self.V(X), self.num_attention_heads, self.attn_head_size\\n        )  # bsz, head, seq_len, head_dim\\n\\n        key_Cp = transpose_for_scores(\\n            self.K(Cp), self.num_attention_heads, self.attn_head_size\\n        )  # bsz, head, pack_len, head_dim\\n        value_Cp = transpose_for_scores(\\n            self.V(Cp), self.num_attention_heads, self.attn_head_size\\n        )  # bsz, head, pack_len, head_dim\\n\\n        ...\\n```\\n\\n:::note\\n\\n`transpose_for_scores` \ucf54\ub4dc\ub97c \uc544\ub798\uc758 \uc720\ud2f8\ub9ac\ud2f0 \ud568\uc218 \ubd80\ubd84\uc5d0\uc11c \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n:::\\n\\n### Unpack Attention\\n\\n\uc774\uc81c Unpack & Sliding Window Attention\uc758 Unpack Attention \ubd80\ubd84\uc744 \ub2e4\ub904\ubd05\uc2dc\ub2e4.\\n\\n\uc77c\ubc18\uc801\uc73c\ub85c self-attention \uacc4\uc0b0 \uc2dc key\uc640 query \ubc31\ud130\uc758 \ub0b4\uc801\uc744 \ud1b5\ud574 \uba3c\uc800 attention score \uacc4\uc0b0\ud558\uace0, \uc774\ub97c \uc815\uaddc\ud654\ud55c \ub2e4\uc74c\uc5d0 value \ubc31\ud130\uc640\uc758 \ub0b4\uc801\uc744 \ud1b5\ud574 context \ubc31\ud130\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4.\\nUnpack & Sliding Window Attention \uc0ac\uc6a9\ud558\ub294 \uacbd\uc6b0\uc5d0 $K(C_p)$\uc640 $K(X)$ \ud569\uce5c $K(X;C_p)$ \ubc31\ud130\uacfc $V(C_p)$\uc640 $V(X)$\uc758 \ud569\uce5c $V(X;C_p)$ \ubc31\ud130\uc758 \ub0b4\uc801\uc744 \ud1b5\ud574 Attention \uacc4\uc0b0\ud569\ub2c8\ub2e4.\\n\\nSliding Window\uc640 Unpack Attention \ubd80\ubd84\uc744 \ub530\ub85c \ucc98\ub9ac\ud558\uba74 Unpack & Sliding Window Attention \uc27d\uac8c \uacc4\uc0b0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n\uc21c\uc11c\ub294 \uc911\uc694\ud558\uc9c0 \uc54a\uc544 Unpack Attention \uba3c\uc800 \uacc4\uc0b0\ud574\ubcfc\uae4c\uc694?\\n\\n#### \ucf54\ub4dc\\n\\n`key_cp_attn[:] -= Dp` \uc8fc\ubaa9\ud558\uc2dc\uc8e0. \uc5ec\uae30\uc11c\ub294 context\ub97c \uacc4\uc0b0\ud558\uae30 \uc804\uc5d0 attention scores\uc5d0\uc11c uniform distance matrix\ub97c \ube8d\ub2c8\ub2e4.\\n\\n```python\\n    # Step 1 calculate the attention scores for the packed data\\n    key_cp_attn = torch.matmul(query, key_Cp.transpose(2, 3))\\n    key_cp_attn = key_cp_attn * rsqrt_d\\n    key_cp_attn[:] -= Dp\\n    key_cp_attn = F.softmax(key_cp_attn, dim=-1)  # bsz, heads, seq_len, pack_len\\n\\n    packed_context = torch_bmm_nd(key_cp_attn, value_Cp, ndim=4)\\n```\\n\\n### Global + Sliding Window\\n\\n<Figure>\\n  <img src={full_sparse_attn_img} />\\n  Figure 3: Full Attention\uacfc Global + Sliding Window Attention \ube44\uad50\\n</Figure>\\n\\nSelf-attention\uc740 $O(n^2)$ (quadratic complexity) \ubb38\uc81c \ub54c\ubb38\uc5d0 512\ubcf4\ub2e4 \ub354 \uae34 \uc785\ub825 \uc2dc\uada8\uc2a4\ub97c \ub2e4\ub8e8\uae30 \ud798\ub4e4\uc9c0\ub9cc, LittleBird \ub17c\ubb38\uc5d0\uc11c \ub098\uc628 sparse attention \uac19\uc740 \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud558\uba74 \uacc4\uc0b0\ub7c9\uc774 \uc904\uc5b4\uc11c \ud720\uc52c \uae34 \uc785\ub825 \uc2dc\ud000\uc2a4\ub97c \ucc98\ub9ac\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n\uc704\uc758 \uc774\ubbf8\uc9c0\uc5d0\uc11c self-attention\uc640 sparse attention\uc758 \ucc28\uc774\ub97c \uc9c1\uc811 \ub208\uc73c\ub85c \ud655\uc778 \ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud558\uc580\uc0c9 \ub0b4\ubaa8\ub4e4\uc740 sparse attention \uc0ac\uc6a9\ud558\ub294 \uacbd\uc6b0\uc5d0 \uacc4\uc0b0\ud558\uc9c0 \uc54a\ub294 attention score \uc785\ub2c8\ub2e4.\\n\\n\uc0ac\uc2e4\uc0c1, Unpack & Sliding Window attention \uc0ac\uc6a9\ud560 \ub54c\ub3c4 $seq\\\\_len$\ubcf4\ub2e4 $block\\\\_size$\uc640 $pack\\\\_len$ \ucda9\ubd84\ud788 \uc791\uc744 \ub54c \uc2dc\uac04 \ubcf5\uc7a1\ub3c4\ub294 O(n) \uc785\ub2c8\ub2e4. \ub354 \uc815\ud655\ud788 \ub9d0\ud558\uc790\uba74, self-attention\uc758 \uc2dc\uac04 \ubcf5\uc7a1\ub3c4\ub294 $O(n^2d)$\uc778\ub370, Unpack & Sliding Window attention\uc758 \uc2dc\uac04 \ubcf5\uc7a1\ub3c4\ub294 $O(l(4b + 2s))$ \uc785\ub2c8\ub2e4.\\n\\nGPU\uc5d0\uc11c \ud6a8\uc728\uc801\uc73c\ub85c sparse multiplication\uc744 \uc218\ud589\ud560 \uc218 \uc5c6\ub2e4\ub294 \uac83\uc774 \uc798 \uc54c\ub824\uc838 \uc788\uae30 \ub54c\ubb38\uc5d0, LittleBird \uae30\ubc18\ud55c BigBird \ub17c\ubb38\uc758 \uc800\uc790\ub4e4\uc740 block sparse attention\uc774\ub780 attention\uc758 key, value, query \ubc31\ud130\ub4e4\uc744 \ube14\ub85d\ud654\ud574\uc11c \ube14\ub85d\ub4e4\ub07c\ub9ac attention\uc744 \uacc4\uc0b0\ud558\ub294 \ubc29\ubc95\uc744 \uc81c\uc548\ud588\uc2b5\ub2c8\ub2e4. \uc774\ub97c \ud1a0\ub300\ub85c LittleBird\uc758 Global + Sliding Window Attention\uc744 \uacc4\uc0b0\ud560 \uc608\uc815\uc785\ub2c8\ub2e4.\\n\\n### \uc785\ub825 \uc2dc\ud000\uc2a4 \ube14\ub85d\ud654\\n\\n<Figure>\\n  <img src={block_tokens_ex_img} />\\n  Figure 4: blockify example with a seq_len of 512 and a block_size of 64\\n</Figure>\\n\\nview \uba54\uc11c\ub4dc\ub97c \uc0ac\uc6a9\ud558\uba74 \uc544\ub798\uc640 \uac19\uc774 \uc785\ub825 \uc2dc\ud000\uc2a4\ub97c \uc27d\uac8c \ube14\ub85d\ud654\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n```python\\nquery_block = query.view(\\n    batch_size,\\n    self.num_attention_heads,\\n    seq_len // self.block_size,\\n    self.block_size,\\n    -1,\\n)\\nkey_x_block = key_x.view(\\n    batch_size,\\n    self.num_attention_heads,\\n    seq_len // self.block_size,\\n    self.block_size,\\n    -1,\\n)\\nvalue_x_block = value_x.view(\\n    batch_size,\\n    self.num_attention_heads,\\n    seq_len // self.block_size,\\n    self.block_size,\\n    -1,\\n)\\n```\\n\\n### \uccab \ub450 \uc904\\n\\n\uccab \ub450 \uc904, \uc911\uac04 \uc904, \ub9c8\uc9c0\ub9c9 \uc904 \uc774\ub807\uac8c \ucd1d \uc138 \ub2e8\uacc4\ub85c attention score \uacc4\uc0b0\ud560 \uc608\uc815\uc785\ub2c8\ub2e4.\\n\\n<Figure>\\n  <img src={first_two_rows_img} />\\n  Figure 5: \uccab \ub450 \uc904 Attention\\n</Figure>\\n\\nSliding window \uacc4\uc0b0 \uc2dc \ube14\ub85d\uc758 \uc21c\uc11c\ub97c \uc720\uc9c0\ud558\uae30 \uc704\ud574 \uccab \ub450 \uc904, \uc911\uac04 \uc904, \ub9c8\uc9c0\ub9c9 \uc904\uc744 \ubd84\ub9ac\ud558\uc5ec \uacc4\uc0b0\ud569\ub2c8\ub2e4. \uc774\ub294 \ub2e4\uc74c \ubd80\ubd84\uc5d0\uc11c \ub354\uc6b1 \uba85\ud655\ud574\uc9c8 \uac81\ub2c8\ub2e4.\\n\\n#### \ucf54\ub4dc\\n\\n\uc774 \ub2e8\uacc4\uc5d0\uc11c \uac01 key, value, query \ubc31\ud130\uc758 \ucc28\uc6d0\uc774 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4:\\n\\n```\\nbatch_size, attn_heads, num_blocks, block_size, head_dim = key_x_block.shape\\n```\\n\\n\uba3c\uc800 \uccab 4\uac1c\uc758 key\uc640 value \ubca1\ud130 \ube14\ub85d, \uccab \ub450\uac1c\uc758 query \ubc31\ud130 \ube14\ub85d \uac01\uac01\uc758 shape \ubcc0\uacbd\ud574 \ubb36\uc2b5\ub2c8\ub2e4.\\n\\n```\\n# Step 2.1. process the first two rows\\nfirst_two_rows_key_matrix = torch.cat(\\n    [\\n        key_x_block[:, :, 0],\\n        key_x_block[:, :, 1],\\n        key_x_block[:, :, 2],\\n        key_x_block[:, :, 3],\\n    ],\\n    dim=2,\\n)\\nfirst_two_rows_value_matrix = torch.cat(\\n    [\\n        value_x_block[:, :, 0],\\n        value_x_block[:, :, 1],\\n        value_x_block[:, :, 2],\\n        value_x_block[:, :, 3],\\n    ],\\n    dim=2,\\n)\\n\\nfirst_two_query_blocks = torch.cat(\\n    [query_block[:, :, 0], query_block[:, :, 1]], dim=2\\n)\\n```\\n\\n\uadf8 \ub2e4\uc74c\uc73c\ub85c\ub294:\\n1. key\uc640 query \ubc31\ud130\uc758 \ub0b4\uc801\uc744 \ud1b5\ud574 attention score \uacc4\uc0b0\\n2. attention score \uc815\uaddc\ud654\\n3. attention score\uc5d0\uc11c BiALiBi distance matrix \ube7c\uae30\\n4. attention mask\\n5. softmax\\n6. \uadf8\ub9ac\uace0 \ub9c8\uc9c0\ub9c9\uc73c\ub85c attention score\uc640 value \ubc31\ud130\uc758 \ub0b4\uc801\uc744 \ud1b5\ud574 context \uacc4\uc0b0\\n\\n```\\nfirst_two_rows_attn = torch_bmm_nd_transpose(\\n    first_two_query_blocks, first_two_rows_key_matrix, ndim=4\\n)\\nfirst_two_rows_attn *= rsqrt_d\\nfirst_two_rows_attn -= D[:, : self.block_size * 2, : self.block_size * 4]\\nfirst_two_rows_attn += (1.0 - self.mask_v[:, :, :self.block_size * 2, :self.block_size * 4]) * attn_penalty\\nfirst_two_rows_attn = F.softmax(first_two_rows_attn, dim=-1)\\n\\nfirst_two_rows_context = torch_bmm_nd(\\n    first_two_rows_attn, first_two_rows_value_matrix, ndim=4\\n)\\n```\\n\\n\ub9c8\uc9c0\ub9c9 \ub2e8\uacc4\uc5d0\uc11c \uccab \ub450 \uc904, \uc911\uac04 \uc904, \ub9c8\uc9c0\ub9c9 \uc904\uc758 context \uac12\ub4e4\uc744 \ud569\uccd0\uc11c \ucd5c\uc885 context \ubc31\ud130\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \ubc31\ud130\ub4e4\uc744 \ube14\ub85d \ucc28\uc6d0 \uae30\uc900\uc73c\ub85c \ud569\uccd0\uc11c \uba3c\uc800 \ubc31\ud130\uc758 shape \ubcc0\uacbd\ud574\uc57c \ud569\ub2c8\ub2e4.\\n\\n```\\n_, __, ftr_3d, ftr_4d = first_two_rows_context.shape\\nfirst_two_rows_context = first_two_rows_context.view(\\n    batch_size, self.num_attention_heads, 2, ftr_3d // 2, ftr_4d\\n)  # bsz, heads, 2(blocks), block_size, block_size*4\\n```\\n\\n### \uc2ac\ub77c\uc774\ub529 \uc708\ub3c4\uc6b0 (\uc911\uac04 \uc904)\\n\\nBigBird \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ud55c sparse attention \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud574 \uc911\uac04 \uc904\uc758 context \uacc4\uc0b0\ud574 \ubcfc\uae4c\uc694?\\n\\n\ud639\uc2dc\ub098 \uc800\uc758 \uc124\uba85\uc5d0 \ubd80\uc871\ud55c \ubd80\ubd84\uc774 \uc788\uc73c\uba74 \ucd94\uac00\ub85c HuggingFace \ube14\ub85c\uadf8<sub>[5]</sub>\uc5d0\uc11c BigBird \ub17c\ubb38 \uc124\uba85\uc744 \uc77d\uc5b4\ubcf4\uc2dc\uace0 \ubd80\uc871\ud55c \ubd80\ubd84\uc744 \ubcf4\ucda9\ud558\uc2dc\ub294\uac8c \uc88b\uc2b5\ub2c8\ub2e4!\\n\\n<Figure>\\n  <img src={middle_rows_img} />\\n  Figure 6: \uc911\uac04 \uc904 attention\\n</Figure>\\n\\n#### \uc6d0\ub9ac\\n\\n\ube14\ub85d\ub41c key \ubc31\ud130\ub97c 2\ubc88 \ubcf5\uc0ac\ud574\uc11c \ub3cc\ub9ac\ub294\ub370, \uc67c\ucabd\uc73c\ub85c \ud55c\ubc88, \uc624\ub978\ucabd\uc73c\ub85c \ud55c\ubc88 \ubc31\ud130\ub97c \ub3cc\ub9bd\ub2c8\ub2e4. \uc774 3\uac1c\uc758 \ubc31\ud130\ub4e4\uc744 \ud569\uce5c \ub2e4\uc74c\uc5d0 query \ubc31\ud130\uc640\uc758 \ub0b4\uc801\uc744 \uacc4\uc0b0\ud558\uba74 \\n\ud55c\ubc88\uc5d0 \uc2ac\ub77c\uc774\ub529 \uc708\ub3c4\uc6b0\uc5d0 \uc788\ub294 \ubaa8\ub4e0 \ud1a0\ud070\ub4e4\uc758 attention score \uacc4\uc0b0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n\ube14\ub85d\ub41c key\uc640 query \ubc31\ud130 \ub0b4\uc801\uc744 \uacc4\uc0b0\ud558\uba74 \ube14\ub85d\ub4e4\ub07c\ub9ac\uc758 attention score\ub9cc \uacc4\uc0b0\uc774 \ub429\ub2c8\ub2e4.\\n\\n\uc544\ub798\uc758 \uc774\ubbf8\uc9c0\uc5d0\uc11c \ub098\uc628 \uac83\ucc98\ub7fc, \ub3cc\ub9ac\uc9c0 \uc54a\uc740 key \ubc31\ud130\ub4e4\uacfc query\uc758 \ub0b4\uc801\uc744 \uacc4\uc0b0\ud558\uba74 \ub300\uac01\uc120\uc5d0 \uc788\ub294 \ud1a0\ud070\ub4e4\ub07c\ub9ac\uc758 attention score\uac00 \uacc4\uc0b0\uc774 \ub429\ub2c8\ub2e4. \\n\uc67c\ucabd\uc774\ub098 \uc624\ub978\ucabd\uc73c\ub85c \ub3cc\ub9b0 key \ubc31\ud130\uacfc query\uc758 \ub0b4\uc801\uc744 \uacc4\uc0b0\ud558\uba74 \ub300\uac01\uc120\uc5d0\uc11c \uc67c\ucabd \ub610\ub294 \uc624\ub978\ucabd\uc5d0 \ud558\ub098 \ub5a8\uc5b4\uc838 \uc788\ub294 \ud1a0\ud070\ub4e4\ub07c\ub9ac\uc758 attention score \uacc4\uc0b0\uc774 \ub429\ub2c8\ub2e4.\\n\\n<Figure>\\n  <img src={sliding_window_broken_down} />\\n  Figure 7: \uc2ac\ub77c\uc774\ub529 \uc708\ub3c4\uc6b0 attention \uacc4\uc0b0 \uc2dc \ub4e4\uc5b4\uac00\ub294 3\uac00\uc9c0\uc758 \ub2e8\uacc4\\n</Figure>\\n\\n\\n#### \uc2ac\ub77c\uc774\ub529 \uc708\ub3c4\uc6b0 \uc54c\uace0\ub9ac\uc998\\n\\n```\\n# step 2.2 calculate the middle part of the matrix\\n# the trick described in the bigbird paper is used\\n\\nmiddle_band_key_matrix = torch.cat(\\n    [\\n        key_x_block[:, :, 1:-2],  # roll back one\\n        key_x_block[:, :, 2:-1],\\n        key_x_block[:, :, 3:],  # roll forward one\\n    ],\\n    dim=3,\\n)\\nmiddle_band_value_matrix = torch.cat(\\n    [\\n        value_x_block[:, :, 1:-2],  # roll back one\\n        value_x_block[:, :, 2:-1],\\n        value_x_block[:, :, 3:],  # roll forward one\\n    ],\\n    dim=3,\\n)\\n\\n\\n\\n# get the diagnol\\nmiddle_band_sliding = torch_bmm_nd_transpose(\\n    query_block[:, :, 2:-1], middle_band_key_matrix, ndim=5\\n)\\nmiddle_band_sliding += (1.0 - self.band_mask) * attn_penalty\\n```\\n\\n\\n#### \uae00\ub85c\ubc8c attention\\n\\n\ucd94\uac00\uc801\uc73c\ub85c \uc911\uac04 \uc904 \ucc98\ub9ac\ud560 \ub54c \uccab\ubc88 \uc9f8\uc758 key \ubc31\ud130 \ube14\ub85d\uacfc \ubaa8\ub4e0 query \ubc31\ud130 \ube14\ub85d\ub4e4\uacfc\uc758 \ub0b4\uc801\uc744 \ud1b5\ud574 \uae00\ub85c\ubc8c attention\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4.\\n\uc774\ub294 \uc704\uc758 \uc774\ubbf8\uc9c0\uc5d0\uc11c \uc8fc\ud669\uc0c9\uc73c\ub85c \ud45c\uc2dc\ub3fc \uc788\uc2b5\ub2c8\ub2e4. \uae00\ub85c\ubc8c attention\uc744 \ub530\ub85c \uacc4\uc0b0\ud55c \ub4a4 \uc2ac\ub77c\uc774\ub529 \uc708\ub3c4\uc6b0 context\uc640 \ud569\uce69\ub2c8\ub2e4.\\n\\n```\\n# get the global\\nmiddle_band_global = torch.einsum(\\n    \\"bhlqd,bhkd->bhlqk\\", query_block[:, :, 2:-1], key_x_block[:, :, 0]\\n)\\nmiddle_band_global += (1.0 - self.mask_block[:,2:-1,:].unsqueeze(3)) * attn_penalty\\n\\nmiddle_band_attn = torch.cat([middle_band_global, middle_band_sliding], dim=-1)\\nmiddle_band_attn *= rsqrt_d\\nmiddle_band_attn -= self.get_middle_band_distances(D)\\nmiddle_band_attn = F.softmax(middle_band_attn, dim=-1)\\n\\nmiddle_band_context = torch.einsum(\\n    \\"bhlqk,bhkd->bhlqd\\",\\n    middle_band_attn[:, :, :, :, : self.block_size],\\n    value_x_block[:, :, 0],\\n)\\nmiddle_band_context += torch_bmm_nd(\\n    middle_band_attn[:, :, :, :, self.block_size : 4 * self.block_size],\\n    middle_band_value_matrix,\\n    ndim=5,\\n)\\n```\\n\\n### \ub9c8\uc9c0\ub9c9 \uc904\\n\\n<Figure>\\n  <img src={last_row_img} />\\n  Figure 8: \ub9c8\uc9c0\ub9c9 \uc904 Attention\\n</Figure>\\n\\n\uccab \ub450 \uc904\uacfc \ube44\uc2b7\ud558\uac8c \uacc4\uc0b0\ud558\ub294\ub370 \uccab 4\uac1c\uc758 \ube14\ub85d \ub300\uc2e0 \uccab\ubc88\uc9f8 \ube14\ub85d\uacfc \ub9c8\uc9c0\ub9c9 3\uac1c\uc758 \ube14\ub85d\ub4e4\uc744 \ud569\uccd0\uc11c query\uc640 \ub0b4\uc801\uc744 \ud1b5\ud574 attention \uacc4\uc0b0\ud569\ub2c8\ub2e4.\\n\\n```\\n# calcualte the last row\\nlast_row_key_matrix = torch.cat(\\n    [\\n        key_x_block[:, :, 0],\\n        key_x_block[:, :, -3],\\n        key_x_block[:, :, -2],\\n        key_x_block[:, :, -1],\\n    ],\\n    dim=2,\\n)\\nlast_row_value_matrix = torch.cat(\\n    [\\n        value_x_block[:, :, 0],\\n        value_x_block[:, :, -3],\\n        value_x_block[:, :, -2],\\n        value_x_block[:, :, -1],\\n    ],\\n    dim=2,\\n)\\n\\nlast_row_attn = torch_bmm_nd_transpose(\\n    query_block[:, :, -1], last_row_key_matrix, ndim=4\\n)\\nlast_row_attn *= rsqrt_d\\nlast_row_attn -= D[:, -self.block_size :, -self.block_size * 4 :]\\nlast_row_attn = F.softmax(last_row_attn, dim=-1)\\n\\nlast_row_context = torch_bmm_nd(last_row_attn, last_row_value_matrix, ndim=4)\\nlast_row_context.unsqueeze_(2)\\n```\\n\\n### \ub9c8\ubb34\ub9ac\\n\\n\ub9c8\uc9c0\ub9c9\uc73c\ub85c \uccab \ub450 \uc904, \uc911\uac04 \uc904, \ub9c8\uc9c0\ub9c9 \uc904\uc758 context\ub4e4\uc744 \ud569\uce5c \ub2e4\uc74c\uc5d0 \uc774\uc758 \ubc31\ud130 shape\uc744 \ubcc0\uacbd\ud558\uace0 unpack context\uc640 \ub354\ud55c \ub2e4\uc74c\uc5d0 \ucd5c\uc885\uc801\uc73c\ub85c \ud55c\ubc88 \ub354 \ub9c8\uc9c0\ub9c9\uc73c\ub85c \ucd5c\uc885 context \ubc31\ud130 shape\uc744 \ubcc0\uacbd\ud569\ub2c8\ub2e4.\\n\\n```\\ncontext_layer = torch.cat(\\n    [first_two_rows_context, middle_band_context, last_row_context], dim=2\\n)\\ncontext_layer = context_layer.view(\\n    (batch_size, self.num_attention_heads, seq_len, -1)\\n)\\n\\nCx = context_layer + packed_context\\nCx = Cx.view(\\n    batch_size, seq_len, self.num_attention_heads * self.attn_head_size\\n) * self.mask_v.squeeze(1)\\n\\nreturn Cx\\n```\\n\\n## BiALiBi\\n\\nBiALiBi distance \ud589\ub82c\uc744 \ub9cc\ub4e4\uae30 \uc704\ud55c \ub2e8\uacc4 \uc138 \uac00\uc9c0 \uc788\uc2b5\ub2c8\ub2e4. \\n\\n\uccab \ubc88\uc9f8\ub85c \ud589\ub82c \ub300\uac01\uc120\uc744 \uae30\uc900\uc73c\ub85c \ub300\uac01\uc120\uc5d0\uc11c \uac01 \uc694\uc18c\uc758 \uac70\ub9ac\uc5d0 \ud574\ub2f9\ud558\ub294 absolute distance \ud589\ub82c\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \\n\ub450 \ubc88\uc9f8\ub85c \u03b3, \u03b2, \u03b1 \uac00\uc911\uce58/\ud30c\ub77c\ubbf8\ud130 \uac12\ub4e4\ub85c \ub9e8 \uc704\uc758 \uacf5\uc2dd\uc5d0\uc11c \ub098\uc628 \uc870\uac74\uc744 \ub9de\ucdb0\uc11c \ud589\ub82c \ub9c8\uc2a4\ud06c \uad6c\ucd95\ud569\ub2c8\ub2e4.\\n\\n\ub9c8\uc9c0\ub9c9\uc73c\ub85c absolute distance \ud589\ub82c\uacfc \ud589\ub82c \ub9c8\uc2a4\ud06c\ub97c \uc131\ubd84\uacf1 (element-wise multiplication)\ud574\uc11c BiALiBi \ud589\ub82c\uc744 \ub9cc\ub4e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n\\n#### 1. distance \ud589\ub82c \ucd08\uae30\ud654\\n\\n```Python\\nrow_i = torch.arange(self.seq_len, dtype=torch.float32)\\ncol_i = torch.arange(self.seq_len, dtype=torch.float32).unsqueeze(-1)\\ndistances = (row_i - col_i).abs()\\ndistances\\n\\ntensor([[0, 1, 2, 3, 4, 5],\\n        [1, 0, 1, 2, 3, 4],\\n        [2, 1, 0, 1, 2, 3],\\n        [3, 2, 1, 0, 1, 2],\\n        [4, 3, 2, 1, 0, 1],\\n        [5, 4, 3, 2, 1, 0]], dtype=torch.int32)\\n```\\n\\n#### 2. gamma(\u03b3) \ubc0f beta(\u03b2) \ub9c8\uc2a4\ud06c\\n\\n```\\ngamma_mask = torch.triu(torch.ones_like(self.distances), diagonal=1)\\ngamma_mask *= self.gamma.view(-1, 1, 1)\\ngamma_mask\\n\\ntensor([[[0.0000, 0.4540, 0.4540, 0.4540, 0.4540, 0.4540],\\n         [0.0000, 0.0000, 0.4540, 0.4540, 0.4540, 0.4540],\\n         [0.0000, 0.0000, 0.0000, 0.4540, 0.4540, 0.4540],\\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.4540, 0.4540],\\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4540],\\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\\n       grad_fn=<MulBackward0>)\\n```\\n\\n```\\nbeta_mask = torch.tril(torch.ones_like(self.distances), diagonal=-1)\\nbeta_mask *= self.beta.view(-1, 1, 1)\\nbeta_mask\\n\\ntensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\\n         [0.9392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\\n         [0.9392, 0.9392, 0.0000, 0.0000, 0.0000, 0.0000],\\n         [0.9392, 0.9392, 0.9392, 0.0000, 0.0000, 0.0000],\\n         [0.9392, 0.9392, 0.9392, 0.9392, 0.0000, 0.0000],\\n         [0.9392, 0.9392, 0.9392, 0.9392, 0.9392, 0.0000]]],\\n       grad_fn=<MulBackward0>)\\n```\\n\\n\\n#### 3. Gamma\uc640 Beta \ub9c8\uc2a4\ud06c\ub97c \ub354\ud55c \ub2e4\uc74c\uc5d0 \ub9c8\uc2a4\ud06c\uc5d0 alpha(\u03b1)\ub97c \uc0bd\uc785\\n\\n```Python\\nmask = beta_mask + gamma_mask\\n\\n# step 4: set the alphas\\nmask[:, 0, :] = 1.0\\nmask[:, :, 0] = 1.0\\nmask[:, 1:, 0] *= self.alpha.unsqueeze(1)\\nmask[:, 0, 1:] *= self.alpha.unsqueeze(1)\\nmask[:, 0, 0] *= 0.0\\n\\ntensor([[[0.0000, 0.7959, 0.7959, 0.7959, 0.7959, 0.7959],\\n         [0.7959, 0.0000, 0.4540, 0.4540, 0.4540, 0.4540],\\n         [0.7959, 0.9392, 0.0000, 0.4540, 0.4540, 0.4540],\\n         [0.7959, 0.9392, 0.9392, 0.0000, 0.4540, 0.4540],\\n         [0.7959, 0.9392, 0.9392, 0.9392, 0.0000, 0.4540],\\n         [0.7959, 0.9392, 0.9392, 0.9392, 0.9392, 0.0000]]],\\n       grad_fn=<CopySlices>)\\n```\\n\\n\ub9c8\uc9c0\ub9c9\uc73c\ub85c \ub9c8\uc2a4\ud06c\uc640 absolute distance \ud589\ub82c\uc744 \uc131\ubd84\uacf1 (element-wise multiplication)\ud574\uc11c BiALiBi \ud589\ub82c\uc744 \ub9cc\ub4ed\ub2c8\ub2e4.\\n\\n```\\nself.distances * mask\\n\\ntensor([[[0.0000, 0.2621, 0.5243, 0.7864, 1.0486, 1.3107],\\n         [0.2621, 0.0000, 0.6620, 1.3239, 1.9859, 2.6478],\\n         [0.5243, 0.4262, 0.0000, 0.6620, 1.3239, 1.9859],\\n         [0.7864, 0.8524, 0.4262, 0.0000, 0.6620, 1.3239],\\n         [1.0486, 1.2787, 0.8524, 0.4262, 0.0000, 0.6620],\\n         [1.3107, 1.7049, 1.2787, 0.8524, 0.4262, 0.0000]]],\\n       grad_fn=<MulBackward0>)\\n```\\n\\n\\n## \uc720\ud2f8\ub9ac\ud2f0 \ud568\uc218\\n\\n\uc544\ub798\uc758 \ud568\uc218\ub4e4\uc740 HuggingFace \uc800\uc7a5\uc18c\uc5d0 \uc788\ub294 BigBird \ubaa8\ub378 \ucf54\ub4dc\uc5d0\uc11c \uac00\uc838\uc640 LittleBird\uc5d0\uc11c \uc4f8 \uc218 \uc788\uac8c \uc0b4\uc9dd \uc218\uc815\ud55c \ud568\uc218\ub4e4\uc774\ub2e4.\\n\\n```\\ndef torch_bmm_nd_transpose(inp_1, inp_2, ndim=None):\\n    \\"\\"\\"Fast nd matrix multiplication with transpose\\"\\"\\"\\n    # faster replacement of torch.einsum (bhqd,bhkd->bhqk)\\n    return torch.bmm(\\n        inp_1.reshape((-1,) + inp_1.shape[-2:]),\\n        inp_2.reshape((-1,) + inp_2.shape[-2:]).transpose(1, 2),\\n    ).view(inp_1.shape[: ndim - 2] + (inp_1.shape[ndim - 2], inp_2.shape[ndim - 2]))\\n\\n\\ndef torch_bmm_nd(inp_1, inp_2, ndim=None):\\n    \\"\\"\\"Fast nd matrix multiplication\\"\\"\\"\\n    # faster replacement of torch.einsum (\\"bhqk,bhkd->bhqd\\")\\n    return torch.bmm(\\n        inp_1.reshape((-1,) + inp_1.shape[-2:]), inp_2.reshape((-1,) + inp_2.shape[-2:])\\n    ).view(inp_1.shape[: ndim - 2] + (inp_1.shape[ndim - 2], inp_2.shape[ndim - 1]))\\n\\n\\ndef transpose_for_scores(x, num_attn_head, attn_head_size):\\n    new_x_shape = x.size()[:-1] + (num_attn_head, attn_head_size)\\n    x = x.view(*new_x_shape)\\n    return x.permute(0, 2, 1, 3)\\n```\\n\\n## \uae30\ud0c0\\n\\n\uc77d\uc5b4\uc8fc\uc154\uc11c \uac10\uc0ac\ud569\ub2c8\ub2e4.\\n\\n\uc804\uccb4 \uc18c\uc2a4\ucf54\ub4dc [Github](https://github.com/jwnz/littlebird)\uc5d0\uc11c \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4!\\n\\n\ub9cc\uc57d\uc5d0 \uc9c8\ubb38\uc774 \uc788\uc73c\uc2dc\uac70\ub098 \uc124\uba85\uc5d0 \ub300\ud574 \uc798\ubabb\ub41c \ubd80\ubd84\uc774 \uc788\uc73c\uba74 \uc704\uc758 Github \uc800\uc7a5\uc18c\uc5d0 \uc774\uc288\ub97c \uc62c\ub824 \uc54c\ub824\uc8fc\uc2dc\uba74 \uc798\ubabb\ub41c \ubd80\ubd84\uc744 \uc218\uc815\ud558\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4! \ud83d\ude0a\\n\\n## \ucc38\uc870\\n\\n- [[1] LittleBird: Efficient Faster & Longer Transformer for Question Answering](https://arxiv.org/abs/2210.11870)\\n- [[2] Big Bird: Transformers for Longer Sequences](https://arxiv.org/abs/2007.14062)\\n- [[3] Luna: Linear Unified Nested Attention](https://arxiv.org/abs/2106.01540)\\n- [[4] Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation](https://arxiv.org/abs/2108.12409)\\n- [[5] Understanding BigBird\'s Block Sparse Attention](https://huggingface.co/blog/big-bird)"}]}')}}]);